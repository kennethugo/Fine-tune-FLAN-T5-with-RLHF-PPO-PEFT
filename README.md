# Fine-tune FLAN-T5 with Reinforcement Learning with Human Feedback, Proximal policy optimzation (PPO) and PEFTT
This repository provides a detailed guide on fine-tuning a large language model with Reinforcement Learning with Human Feedback (RLHF). In this case a pretrained Flan-T5 model from HuggingFace is fine-tuned using RLHF with Parameter Efficient Fine-Tuning (PEFT) - LoRA and proximal policy optimization (PPO)to get a more positive and less toxic dialogue summarization the new model.


# Table of Content
* [**Introduction**](##Introduction)
* [**Getting Started**](##Getting-Started)
* [**Methodology and Results**](##Methodology-and-Results)
* [**Conclusion** ](##Conclusion)
* [**Further work** ](##Further-work)
